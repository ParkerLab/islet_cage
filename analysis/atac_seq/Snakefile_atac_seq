#
# The Parker Lab (theparkerlab.org)
# University of Michigan, Ann Arbor
#

import pandas
import numpy
import itertools
import os
import sys
import functools
import math

workdir: config['results']

# SAMPLE INFO
sdf = pandas.read_csv(config['sample_info'], sep='\t')

if config['libraries'] != "":
    LIBRARIES = config['libraries']
else:
    LIBRARIES = sdf['library'].drop_duplicates().tolist()

SCRIPTS = config['scripts']

# GENERIC DATA

ORGANISMS = {
    'rn4': 'rat',
    'rn5': 'rat',
    'mm9': 'mouse',
    'mm10': 'mouse',
    'hg19': 'human',
    'hg38': 'human'
}

AUTOSOMAL_REFERENCES = {
    'hg19': ['chr{}'.format(i) for i in range(1, 23)],
    'hg38': ['chr{}'.format(i) for i in range(1, 23)],
    'mm9': ['chr{}'.format(i) for i in range(1, 20)],
    'mm10': ['chr{}'.format(i) for i in range(1, 20)],
    'rn4': ['chr{}'.format(i) for i in range(1, 21)],
    'rn5': ['chr{}'.format(i) for i in range(1, 21)]
}

MACS2_GENOME_SIZE = {
    'rn4': 'mm',
    'rn5': 'mm',
    'mm9': 'mm',
    'mm10': 'mm',
    'hg19': 'hs',
    'hg38': 'hs'
}


# set path generator function
prefix_results = functools.partial(os.path.join, config['results'])

# target directories; relative to root
FASTQC_DIR = prefix_results('fastqc')
TRIM_DIR = prefix_results('trim')
BWA_DIR = prefix_results('bwa')
MERGE_DIR = prefix_results('merge_readgroups')
MD_DIR = prefix_results('mark_duplicates')
PRUNE_DIR = prefix_results('prune')
MACS2_DIR = prefix_results('macs2')
ATAQV_DIR = prefix_results('ataqv')
MKARV_DIR = prefix_results('mkarv')
VSIGNAL_DIR = prefix_results('vplots')
COVERAGES_DIR = prefix_results('coverages')
FINAL_PEAKS = prefix_results('final_peaks')
# Subsample dirs
SUBSAMPLE_DIR = prefix_results('subsampled_bam')
MACS2_SUB_DIR = prefix_results('subsampled_macs2')

# logs and other stuff
LOG_DIR = prefix_results('logs')
VERSION_DIR = prefix_results('versions')


# Helper functions

def get_genome(library):
    try:
        genome = sdf[sdf['library'] == library].iloc[0]['genome']
    except IndexError:
        try:
          genome = sdf[sdf['tissue'] == library].iloc[0]['genome']
        except IndexError:
            print("library does not have genome info! WARNING: assuming hg19")
            genome = "hg19"
    return(genome)


def get_organism(genome):
    return ORGANISMS[genome]


def get_bwa_index(genome):
    return config['bwa_index'][genome]


def get_autosomes(genome):
    return AUTOSOMAL_REFERENCES[genome]


def get_tss(genome):
    return config['tss'][genome]


def get_whitelists(genome):
    if genome in config['whitelist']:
        return config['whitelist'][genome]
    else:
        return None


def get_blacklists(genome):
    if genome in config['blacklist']:
        return config['blacklist'][genome]
    else:
        return None


def mappability_filter(wildcards):
    bed = os.path.join(MACS2_DIR, f'{wildcards.subsample_type}/{wildcards.library}_peaks.{wildcards.peak_type}Peak')
    genome = get_genome(wildcards.library)
    
    whitelists = get_whitelists(genome) or []
    blacklists = get_blacklists(genome) or []

    whitelist_template = 'intersectBed -a {} -b {} -f 1.0'
    whitelist_chain = ' | '.join([whitelist_template.format('stdin', x)
                                  for x in whitelists])

    blacklist_template = 'intersectBed -a {} -b {} -v'
    blacklist_chain = ' | '.join(
        [blacklist_template.format('stdin', x) for x in blacklists])

    command = ' | '.join([x for x in ['cat {bed}'.format(
        **locals()), whitelist_chain, blacklist_chain] if x != ''])
    return command


def get_library_type(library):
    """Library is single ended is read2 column cell is NAN, else double end """
    if config['uniform_end'] == "single_end":
        return config['uniform_end']
    else:
        try :
            math.isnan(float(sdf[sdf['library'] == library].iloc[0]['read2']))
            out = "single_end"
        except ValueError:
            out = "double_end"
        return out


def get_trimmed_fastq_path(readgroup, readnum):
    fastq_basename = sdf[sdf['readgroup'] == readgroup].iloc[0]['read_base']
    return os.path.join(TRIM_DIR, f"{fastq_basename}.{readnum}.trimmed.fastq.gz")


def get_fastqs_for_libraries(libraries, read):
    flist = sdf[sdf['library'].isin(libraries)][read].tolist()
    return [x for x in flist if not pandas.isnull(x)]


def get_required_fastqs(libraries):
    read1_list = get_fastqs_for_libraries(libraries, 'read1')
    read2_list = get_fastqs_for_libraries(libraries, 'read2')
    return [os.path.basename(x).replace(".fastq.gz", "").replace(".fastq", "") for x in read1_list + read2_list]
    

def get_fastq_for_fastqc(wildcards):
    all_fastq_list = get_fastqs_for_libraries(LIBRARIES, 'read1') + get_fastqs_for_libraries(LIBRARIES, 'read2')
    for fastq in all_fastq_list:
        if os.path.basename(fastq).replace(".fastq.gz", "").replace(".fastq", "") == wildcards.fastq:
            return fastq
    print("required fastq not found")
    sys.exit(1)


def getPruneFlags(wildcards):
    seqEnd = get_library_type(wildcards.library)
    if seqEnd == "single_end":
        return " -F 4 "
    elif seqEnd == "double_end":
        return " -f 3 -F 4 -F 8"

SUBSAMPLING = expand("subsamp_{depth}_merged", depth = [dep for dep in config['subsample_type'] if dep != "unsubsampled"] )
if "unsubsampled" in config['subsample_type']:
    SUBSAMPLING = SUBSAMPLING + ["unsubsampled"]

    
rule all:
    input:
        peaks = expand(os.path.join(FINAL_PEAKS, "{tissue}.{peak_type}Peaks_fdr0.01_noBlacklist.bed"),
                       tissue = config['select_peaks'].keys(),
                       peak_type = config['peak_type']),
        # blacklist_filtered_peaks = expand(os.path.join(MACS2_DIR, "{subsample_type}",
        #                                                '{library}_peaks.{peak_type}Peak.noblacklist'),
        #                                   subsample_type = SUBSAMPLING,
        #                                   library = LIBRARIES,
        #                                   peak_type = config['peak_type']),
        # fastqc = expand(os.path.join(FASTQC_DIR, '{fastq}_fastqc.zip'),
        #                 fastq = get_required_fastqs(LIBRARIES)),
        # cov = os.path.join(COVERAGES_DIR, 'coverages.txt'),
        # bam_me = expand(os.path.join(PRUNE_DIR, '{tissue}.subsamp_{subsample_type}_merged.bam'),
        #                 tissue = ['Islets','SkeletalMuscle','endoC','Adipose'],
        #                 subsample_type = 13571561),
        # bam = expand(os.path.join(SUBSAMPLE_DIR, '{library}.subsampled_{subsample_type}.bam'), subsample_type = 13571561, library = LIBRARIES),


        # ataqv = expand(os.path.join(ATAQV_DIR, '{subsample_type}', '{library}.ataqv.json.gz'),
        #                subsample_type = config['subsample_type'], 
        #                library = LIBRARIES)

        # # v-plots output
        # [os.path.join(VSIGNAL_DIR, '{}.png'.format(x))
        #  for x in config['libraries']],

        #
        # software versions
        #
        # os.path.join(VERSION_DIR, 'fastqc_version.txt'),
        # os.path.join(VERSION_DIR, 'cta_version.txt'),
        # os.path.join(VERSION_DIR, 'bwa_version.txt'),
        # os.path.join(VERSION_DIR, 'picard_version.txt'),
        # os.path.join(VERSION_DIR, 'samtools_version.txt'),
        # os.path.join(VERSION_DIR, 'macs2_version.txt'),
        # os.path.join(VERSION_DIR, 'bedtools_version.txt'),
        # os.path.join(VERSION_DIR, 'ataqv_version.txt')


rule fastqc:
    """Run fastqc """
    input:
        get_fastq_for_fastqc 
    output:
        os.path.join(FASTQC_DIR, '{fastq}_fastqc.zip')
    params:
        outdir = FASTQC_DIR
    log:
        os.path.join(LOG_DIR, 'fastqc.{fastq}.log')
    shell:
        'fastqc {input} -o {params.outdir} &> {log}'


rule trim:
    """Trim using cta """
    input:
        first = lambda wildcards: sdf[sdf['read_base'] == wildcards.fastq_basename].iloc[0]['read1'],
        second = lambda wildcards: sdf[sdf['read_base'] == wildcards.fastq_basename].iloc[0]['read2'],
    output:
        first = os.path.join(TRIM_DIR, '{fastq_basename}.read1.trimmed.fastq.gz'),
        second = os.path.join(TRIM_DIR, '{fastq_basename}.read2.trimmed.fastq.gz')
    resources:
        io_limit = 1
    shell:
        ' ionice -c2 -n7 cta {input.first} {input.second} '
        ' {output.first} {output.second} '
        
    
rule map_paired_end:
    input:
        first = lambda wildcards: get_trimmed_fastq_path(wildcards.readgroup, "read1"),
        second = lambda wildcards: get_trimmed_fastq_path(wildcards.readgroup, "read2"),
        fasta = lambda wildcards: get_bwa_index(get_genome(wildcards.library))
    output:
        os.path.join(BWA_DIR, "double_end", '{library}______{readgroup}.bam')
    params:
        sort_tmp = os.path.join(
            BWA_DIR, "double_end", '{library}______{readgroup}.sort.tmp'),
        rg = '\\t'.join(['@RG', 'ID:{}'.format('{readgroup}'),
                         'LB:{}'.format('{library}')])
    threads:
        8
    conda:
        config['map_env']
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 15000 + 15000
    log:
        bwa = os.path.join(LOG_DIR, 'map.bwa.{library}______{readgroup}.log'),
        samtools = os.path.join(LOG_DIR, 'map.samtools.{library}______{readgroup}.log')
    shell:
        ' ionice -c2 -n7 bwa mem -I 200,200,5000 '
        ' -M -R "{params.rg}"'
        ' -t {threads} '
        ' {input.fasta} {input.first} {input.second} 2> {log.bwa} | '
        ' samtools sort -m 1g -@ {threads} -O bam '
        ' -T {params.sort_tmp} -o {output} - 2> {log.samtools} '


def get_adapter_list():
    adapter_sequences = pandas.read_csv(config['cutadapt']['adapters'], sep='\t')['sequence'].drop_duplicates().tolist()
    alist = ' '.join(f"-a {seq}" for seq in adapter_sequences )
    return alist


def get_fastq_for_cutadapt(wildcards):
    sdf['cutadapt_base'] = sdf['read1'].map(os.path.basename)
    fastq = sdf[sdf['cutadapt_base'] == wildcards.fastq_basename].iloc[0]['read1']
    return fastq


rule cutadapt:
    """Trim adapter sequences """
    input:
        fastq = get_fastq_for_cutadapt
    output:
        trimmed = os.path.join(TRIM_DIR, "{fastq_basename}.trimmed.fastq.gz")
    params:
        adapter = get_adapter_list(),
        trim = config['cutadapt']['trim_reads_to'],
    shell:
        ' cutadapt {params.adapter} '
        ' {params.trim} '
        ' -o {output.trimmed} '
        ' {input.fastq} '
        

def get_cutadapt_trimmed_fastq_name(wildcards):
    fastq_path = sdf[sdf['readgroup'] == wildcards.readgroup].iloc[0]['read1']
    fastq_basename = os.path.basename(fastq_path)
    trimmed_file = os.path.join(TRIM_DIR, f"{fastq_basename}.trimmed.fastq.gz") 
    return trimmed_file


rule map_single_end:
    """Get read 1 fastq trimmed using cutadapt to map """
    input:
        first = get_cutadapt_trimmed_fastq_name,
        fasta = lambda wildcards: get_bwa_index(get_genome(wildcards.library))
    output:
        os.path.join(BWA_DIR, "single_end", '{library}______{readgroup}.bam')
    params:
        sort_tmp = os.path.join(
            BWA_DIR, "single_end", '{library}______{readgroup}.sort.tmp'),
        rg = '\\t'.join(['@RG', 'ID:{}'.format('{readgroup}'),
                         'LB:{}'.format('{library}')])
    threads:
        8
    conda:
        config['map_env']
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 15000 + 15000
    log:
        bwa = os.path.join(LOG_DIR, 'map.bwa.{library}______{readgroup}.log'),
        samtools = os.path.join(LOG_DIR, 'map.samtools.{library}______{readgroup}.log')
    shell:
        ' ionice -c2 -n7 bwa mem -I 200,200,5000 '
        ' -M -R "{params.rg}"'
        ' -t {threads} '
        ' {input.fasta} {input.first} 2> {log.bwa} | '
        ' samtools sort -m 1g -@ {threads} -O bam '
        ' -T {params.sort_tmp} -o {output} - 2> {log.samtools} '

        
rule merge:
    """merge files in each readgroup"""
    input:
        bams = lambda wildcards: expand(os.path.join(BWA_DIR, '{end}', '{{library}}______{readgroup}.bam'),
                                        end = get_library_type(wildcards.library),
                                        readgroup = sdf[sdf['library'] == wildcards.library]['readgroup'].tolist())
    output:
        bam = os.path.join(MERGE_DIR, '{library}.bam'),
        bam_index = os.path.join(MERGE_DIR, '{library}.bam.bai'),
        unsorted = temp(os.path.join(MERGE_DIR, '{library}.unsorted.bam')),
    resources:
        io_limit = 1,
    params:
        sort_tmp_prefix = os.path.join(MERGE_DIR, '{library}.sort')
    shell:
        """
        ionice -c2 -n7 samtools merge {output.unsorted} {input.bams} ;
        ionice -c2 -n7 samtools sort -m 1G -O bam -T {params.sort_tmp_prefix} \
            -o {output.bam} {output.unsorted} ;
        samtools index {output.bam}
        """

        
rule mark_duplicates:
    """Use picard to mark duplicates """
    input:
        bam = rules.merge.output.bam,
        bam_index = rules.merge.output.bam_index
    output:
        bam = os.path.join(MD_DIR, '{library}.md.bam'),
        bam_index = os.path.join(MD_DIR, '{library}.md.bam.bai')
    params:
        metrics = os.path.join(MD_DIR, '{library}.metrics'),
        tmp_dir = MD_DIR
    shell:
        ' ionice -c2 -n7 picard '
        ' -m 4g MarkDuplicates '
        ' I={input.bam} '
        ' O={output.bam} '
        ' ASSUME_SORTED=true '
        ' METRICS_FILE={params.metrics} '
        ' VALIDATION_STRINGENCY=LENIENT '
        ' TMP_DIR={params.tmp_dir} ;'
        ' samtools index {output.bam} '

        
rule prune:
    """Retain properly paired uniquely mapped and all that jazz """
    input:
        bam = rules.mark_duplicates.output.bam,
        bam_index = rules.mark_duplicates.output.bam_index
    output:
        bam = os.path.join(PRUNE_DIR, '{library}.pruned.bam'),
        bam_index = os.path.join(PRUNE_DIR, '{library}.pruned.bam.bai')
    params:
        tmp_dir = MD_DIR,
        mapq = 30,
        prune = getPruneFlags,
        autosomes = lambda wildcards: get_autosomes(
            get_genome(f'{wildcards.library}'))
    resources:
        io_limit = 1
    shell:
        ' ionice -c2 -n7 samtools view -b -h '
        ' {params.prune} '
        ' -F 256 -F 1024 -F 2048 '
        ' -q {params.mapq} {input.bam} '
        ' {params.autosomes} > {output.bam} ;'
        ' samtools index {output.bam} '


def get_bam_to_call_peaks(wildcards):
    if wildcards.subsample_type == "unsubsampled":
        return os.path.join(PRUNE_DIR, f'{wildcards.library}.pruned.bam')
    else:
        return os.path.join(SUBSAMPLE_DIR, f'{wildcards.library}.{wildcards.subsample_type}.bam')

        
rule peaks:
    """Use MACS2 to call peaks """
    input:
        get_bam_to_call_peaks
    output:
        os.path.join(MACS2_DIR, '{subsample_type}', '{library}_peaks.{peak_type}Peak')
    params:
        genome_size = lambda wildcards: MACS2_GENOME_SIZE[get_genome(wildcards.library)],
        peak_type = lambda wildcards: "--broad" if wildcards.peak_type == "broad" else "",
        outdir = os.path.join(MACS2_DIR, '{subsample_type}')
    conda:
        config['peak_env']
    log:
        mylog = os.path.join(MACS2_DIR, '{subsample_type}', '{library}.macs2_{peak_type}Peak.log'),
    shell:
        ' ionice -c2 -n7 macs2 callpeak '
        ' -t {input} '
        ' --outdir {params.outdir} '
        ' -f BAM '
        ' -n {wildcards.library} '
        ' -g {params.genome_size} '
        ' --nomodel '
        ' --shift -100 '
        ' --seed 762873 '
        ' --extsize 200 '
        ' -B '
        ' {params.peak_type} '
        ' --keep-dup all &> {log.mylog} '


rule blacklist_filter:
    """Keep whitelist regions, remove blacklist regions if respective files are supplied in config """
    input:
        rules.peaks.output
    output:
        os.path.join(MACS2_DIR, '{subsample_type}', '{library}_peaks.{peak_type}Peak.noblacklist')
    params:
        filter_cmd = mappability_filter
    resources:
        io_limit = 1
    shell:
        """
        echo -e "{params.filter_cmd}" ;
        ionice -c2 -n7 {params.filter_cmd} > {output}
        """

#
# Subsampling pipeline
#
rule get_bam_coverages:
    input:
        bam = rules.prune.output.bam
    output:
        cov = temp(os.path.join(COVERAGES_DIR, '{library}.txt')),
    shell:
        r"""samtools view -c {input.bam} | awk '{{print $0"\t{wildcards.library}" }}' OFS='\t' > {output.cov} """

rule assemble_coverages:
    input:
        dat = expand(rules.get_bam_coverages.output.cov, library = LIBRARIES)
    output:
        cov = os.path.join(COVERAGES_DIR, 'coverages.txt'),
    shell:
        """
        cat {input.dat} > {output.cov}
        """
        
rule subsample_bam:
    input:
        bam = rules.prune.output.bam
    output:
        bam = os.path.join(SUBSAMPLE_DIR, '{library}.subsampled_{subsample_type}.bam'),
        tem = temp(os.path.join(SUBSAMPLE_DIR, '{library}.subsampled_{subsample_type}.temp.bam')),
        index = os.path.join(SUBSAMPLE_DIR, '{library}.subsampled_{subsample_type}.bam.bai'),
    params:
        script = SCRIPTS['subsample_bam'],
        output_prefix = os.path.join(SUBSAMPLE_DIR, '{library}.subsampled_{subsample_type}')
    log:
        mylog = os.path.join(SUBSAMPLE_DIR, '{library}.subsampled_{subsample_type}.log')
    shell:
        ' python {params.script} '
        ' --bam {input.bam} '
        ' --coverage {wildcards.subsample_type} '
        ' --output_prefix {params.output_prefix}'
        ' --log {log.mylog}'


def get_subsampled_samples_for_tissue(wildcards):
    d = {'Islets' : [1, 2],
         'SkeletalMuscle' : [1, 2],
         'endoC' : [2, 3],
         'Adipose' : [1, 3]}
    files = [os.path.join(SUBSAMPLE_DIR, f'{wildcards.tissue}{sample}.subsampled_{wildcards.subsample_type}.bam') for sample in d[wildcards.tissue]]
    return files


rule merge_within_tissue:
    input:
        get_subsampled_samples_for_tissue
    output:
        bam = os.path.join(SUBSAMPLE_DIR, '{tissue}.subsamp_{subsample_type}_merged.bam'),
        unsorted = temp(os.path.join(SUBSAMPLE_DIR, '{tissue}.subsamp_{subsample_type}_merged.unrosted.bam')),
        index = os.path.join(SUBSAMPLE_DIR, '{tissue}.subsamp_{subsample_type}_merged.bam.bai'),
    params:
        sort_tmp_prefix = os.path.join(SUBSAMPLE_DIR, '{tissue}.subsamp_{subsample_type}_merged.sort')
    shell:
        """
        ionice -c2 -n7 samtools merge {output.unsorted} {input} ;
        ionice -c2 -n7 samtools sort -m 1G -O bam -T {params.sort_tmp_prefix} \
            -o {output.bam} {output.unsorted} ;
        samtools index {output.bam}
        """


def select_peaks(wildcards):
    subsample_type = "subsamp_{depth}_merged".format(depth = config['select_peaks'][wildcards.library])
    path = os.path.join(MACS2_DIR, f'{subsample_type}', f'{wildcards.library}_peaks.{wildcards.peak_type}Peak.noblacklist')
    return path

rule final_peaks:
    input:
        peak = select_peaks
    output:
        peaks = os.path.join(FINAL_PEAKS, "{library}.{peak_type}Peaks_fdr0.01_noBlacklist.bed"),
    shell:
        r"""
        less {input.peak} | 
        awk '{{if (($9>=2)) print $0}}' OFS='\t' | 
        sortBed -i - | 
        mergeBed -i - > {output.peaks} """
##
# debug info
##
rule versions:
    output:
        fastqc_version = os.path.join(VERSION_DIR, 'fastqc_version.txt'),
        cta_version = os.path.join(VERSION_DIR, 'cta_version.txt'),
        bwa_version = os.path.join(VERSION_DIR, 'bwa_version.txt'),
        picard_version = os.path.join(VERSION_DIR, 'picard_version.txt'),
        samtools_version = os.path.join(VERSION_DIR, 'samtools_version.txt'),
        macs2_version = os.path.join(VERSION_DIR, 'macs2_version.txt'),
        bedtools_version = os.path.join(VERSION_DIR, 'bedtools_version.txt'),
        ataqv_version = os.path.join(VERSION_DIR, 'ataqv_version.txt')
    run:
        shell('fastqc --version &> {output.fastqc_version} || echo ""')
        shell('cta --version &> {output.cta_version} || echo ""')
        shell('bwa &> {output.bwa_version} || echo ""')
        shell(('picard MarkDuplicates --version &> {output.picard_version} || '
               'echo ""'))
        shell('samtools --version &> {output.samtools_version} || echo ""')
        shell('macs2 --version &> {output.macs2_version} || echo ""')
        shell('bedtools --version &> {output.bedtools_version} || echo ""')
        shell('ataqv --version &> {output.ataqv_version} || echo ""')

##
# notification
##

onerror:
    print("Error: Snakemake aborted!")
    shell(
        ("mail -s 'Snakemake ATAC-seq error' "
         "{config[email]} < {log}")
    )

    
onsuccess:
    print("Success: Snakemake completed!")
    shell(
        ("mail -s 'Snakemake ATAC-seq Completed' "
         "{config[email]} < {log}")
    )
